{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeab721d",
   "metadata": {},
   "source": [
    "Data Preprocessing:\n",
    "\n",
    "- Drop the first column which is an index.\n",
    "- Handle any missing values.\n",
    "- Convert categorical variables using Label Encoding.\n",
    "- Split the data into features (X) and target (y).\n",
    "- Split these into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d057df98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "      <th>bmi_imp</th>\n",
       "      <th>smoking_status_imp</th>\n",
       "      <th>rounded_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>202.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "      <td>28.1</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  gender   age  hypertension  heart_disease ever_married  \\\n",
       "0           0    Male  67.0             0              1          Yes   \n",
       "1           1  Female  61.0             0              0          Yes   \n",
       "2           2    Male  80.0             0              1          Yes   \n",
       "3           3  Female  49.0             0              0          Yes   \n",
       "4           4  Female  79.0             1              0          Yes   \n",
       "\n",
       "       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
       "0        Private          Urban             228.69  36.6  formerly smoked   \n",
       "1  Self-employed          Rural             202.21   NaN     never smoked   \n",
       "2        Private          Rural             105.92  32.5     never smoked   \n",
       "3        Private          Urban             171.23  34.4           smokes   \n",
       "4  Self-employed          Rural             174.12  24.0     never smoked   \n",
       "\n",
       "   stroke  bmi_imp smoking_status_imp  rounded_age  \n",
       "0       1     36.6    formerly smoked           67  \n",
       "1       1     28.1       never smoked           61  \n",
       "2       1     32.5       never smoked           80  \n",
       "3       1     34.4             smokes           49  \n",
       "4       1     24.0       never smoked           79  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load the data\n",
    "file_path = 'stroke_data_cleaned.csv'\n",
    "stroke_data = pd.read_csv(file_path)\n",
    "\n",
    "# Quick look at the dataset\n",
    "stroke_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b3e116",
   "metadata": {},
   "source": [
    "- The index column was removed.\n",
    "- Missing values in 'bmi' were filled with the imputed values.\n",
    "- Categorical variables were encoded.\n",
    "- The dataset was split into features and the target variable, and then into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d165697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91e0b21a",
   "metadata": {},
   "source": [
    "Now let's proceed with training the Decision Tree and Random Forest classifiers. After training, we will evaluate them using accuracy and a classification report, which includes precision, recall, and F1-score for both models. Let's start with the Decision Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5420b1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(gender                  0\n",
       " age                     0\n",
       " hypertension            0\n",
       " heart_disease           0\n",
       " ever_married            0\n",
       " work_type               0\n",
       " Residence_type          0\n",
       " avg_glucose_level       0\n",
       " bmi                   201\n",
       " smoking_status          0\n",
       " stroke                  0\n",
       " bmi_imp                 0\n",
       " smoking_status_imp      0\n",
       " rounded_age             0\n",
       " dtype: int64,\n",
       "    gender   age  hypertension  heart_disease  ever_married  work_type  \\\n",
       " 0       1  67.0             0              1             1          2   \n",
       " 1       0  61.0             0              0             1          3   \n",
       " 2       1  80.0             0              1             1          2   \n",
       " 3       0  49.0             0              0             1          2   \n",
       " 4       0  79.0             1              0             1          3   \n",
       " \n",
       "    Residence_type  avg_glucose_level   bmi  smoking_status  stroke  bmi_imp  \\\n",
       " 0               1             228.69  36.6               1       1     36.6   \n",
       " 1               0             202.21  28.1               2       1     28.1   \n",
       " 2               0             105.92  32.5               2       1     32.5   \n",
       " 3               1             171.23  34.4               3       1     34.4   \n",
       " 4               0             174.12  24.0               2       1     24.0   \n",
       " \n",
       "   smoking_status_imp  rounded_age  \n",
       " 0    formerly smoked           67  \n",
       " 1       never smoked           61  \n",
       " 2       never smoked           80  \n",
       " 3             smokes           49  \n",
       " 4       never smoked           79  )"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the 'Unnamed: 0' column as it's just an index\n",
    "stroke_data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "# Check for any remaining missing values\n",
    "missing_values = stroke_data.isnull().sum()\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_columns = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
    "\n",
    "for column in categorical_columns:\n",
    "    stroke_data[column] = label_encoder.fit_transform(stroke_data[column])\n",
    "\n",
    "# Fill missing values in 'bmi' with the imputed values in 'bmi_imp'\n",
    "stroke_data['bmi'].fillna(stroke_data['bmi_imp'], inplace=True)\n",
    "\n",
    "# Separate the dataset into X (features) and y (target)\n",
    "X = stroke_data.drop(['stroke'], axis=1)  # features\n",
    "y = stroke_data['stroke']  # target\n",
    "\n",
    "# Split the data into training and testing sets (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Display the processed data and the missing values (if any)\n",
    "processed_data_head = stroke_data.head()\n",
    "missing_values, processed_data_head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a624fac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8764572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c91ca59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9178082191780822,\n",
       " '              precision    recall  f1-score   support\\n\\n           0       0.96      0.96      0.96       972\\n           1       0.15      0.14      0.14        50\\n\\n    accuracy                           0.92      1022\\n   macro avg       0.55      0.55      0.55      1022\\nweighted avg       0.92      0.92      0.92      1022\\n',\n",
       " 0.949119373776908,\n",
       " '              precision    recall  f1-score   support\\n\\n           0       0.95      1.00      0.97       972\\n           1       0.00      0.00      0.00        50\\n\\n    accuracy                           0.95      1022\\n   macro avg       0.48      0.50      0.49      1022\\nweighted avg       0.90      0.95      0.93      1022\\n')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding the 'smoking_status_imp' column. \n",
    "stroke_data['smoking_status_imp'] = label_encoder.fit_transform(stroke_data['smoking_status_imp'])\n",
    "\n",
    "# Drop the original 'smoking_status' column since 'smoking_status_imp' is its encoded version\n",
    "stroke_data.drop('smoking_status', axis=1, inplace=True)\n",
    "\n",
    "# Redefine X and y with the updated dataset\n",
    "X = stroke_data.drop(['stroke'], axis=1)  # features\n",
    "y = stroke_data['stroke']  # target\n",
    "\n",
    "# Split the data again into training and testing sets (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train the Decision Tree classifier again\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "dt_predictions = dt_classifier.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "dt_classification_report = classification_report(y_test, dt_predictions)\n",
    "\n",
    "# Train the Random Forest classifier again\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "rf_predictions = rf_classifier.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "rf_classification_report = classification_report(y_test, rf_predictions)\n",
    "\n",
    "(dt_accuracy, dt_classification_report, rf_accuracy, rf_classification_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09abcb30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5091d235",
   "metadata": {},
   "source": [
    "The models have been trained and evaluated. Here are the results:\n",
    "\n",
    "Decision Tree Classifier:\n",
    "\n",
    "Accuracy: 91.78%\n",
    "Precision for classifying stroke: 15%\n",
    "Recall for classifying stroke: 14%\n",
    "F1-score for classifying stroke: 14%\n",
    "Random Forest Classifier:\n",
    "\n",
    "Accuracy: 94.91%\n",
    "Precision for classifying stroke: 0% (indicating no stroke cases were correctly predicted)\n",
    "Recall for classifying stroke: 0% (no true positive predictions for stroke cases)\n",
    "F1-score for classifying stroke: 0% (due to no positive predictions for stroke)\n",
    "The accuracy metric might be misleading due to the imbalanced nature of the dataset. Most of the data belongs to the non-stroke class, which the classifiers are likely predicting almost exclusively. This is why we see high overall accuracy but very low precision and recall for the actual stroke predictions.\n",
    "\n",
    "For imbalanced datasets, accuracy is not the best metric. Instead, one should consider using the F1-score, precision, recall, and ROC-AUC scores to evaluate model performance on the minority class, which in this case is the occurrence of a stroke. The Random Forest classifier didn't predict any stroke cases correctly, which suggests it may not be the best model without further tuning or addressing the class imbalance more effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c13d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28b9dfc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9500978473581213,\n",
       " '              precision    recall  f1-score   support\\n\\n           0       0.95      1.00      0.97       972\\n           1       0.00      0.00      0.00        50\\n\\n    accuracy                           0.95      1022\\n   macro avg       0.48      0.50      0.49      1022\\nweighted avg       0.90      0.95      0.93      1022\\n')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Random Forest trained and its predictions are trained. \n",
    "# However, I will now train it again with a different approach for handling the class imbalance.\n",
    "# This time I will adjust class weights within the Random Forest classifier.\n",
    "\n",
    "# Train the Random Forest classifier with class weight adjustment\n",
    "rf_classifier_balanced = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "rf_classifier_balanced.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set with the balanced classifier\n",
    "rf_balanced_predictions = rf_classifier_balanced.predict(X_test)\n",
    "\n",
    "# Evaluate the Random Forest classifier with class weight adjustment\n",
    "rf_balanced_accuracy = accuracy_score(y_test, rf_balanced_predictions)\n",
    "rf_balanced_classification_report = classification_report(y_test, rf_balanced_predictions)\n",
    "\n",
    "(rf_balanced_accuracy, rf_balanced_classification_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3110e7",
   "metadata": {},
   "source": [
    "After training the Random Forest classifier with class weights adjusted to account for the imbalance, the results are:\n",
    "\n",
    "- Accuracy: 95.01%\n",
    "- Precision for classifying stroke: 0% (still indicating no stroke cases were correctly predicted)\n",
    "- Recall for classifying stroke: 0% (no true positive predictions for stroke cases)\n",
    "- F1-score for classifying stroke: 0% (due to no positive predictions for stroke)\n",
    "\n",
    "Adjusting the class weights did not change the classifier's ability to correctly predict the minority class, which in this dataset is the occurrence of a stroke. The classifier is still biased towards predicting the majority class, which suggests that we might need to employ more sophisticated methods to handle the imbalance, such as SMOTE for oversampling the minority class, more complex model tuning, or using different evaluation metrics that focus on the performance on the minority class, such as the ROC-AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9b136e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "187c9d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.700587084148728,\n",
       " '              precision    recall  f1-score   support\\n\\n           0       0.99      0.69      0.82       972\\n           1       0.12      0.82      0.21        50\\n\\n    accuracy                           0.70      1022\\n   macro avg       0.55      0.76      0.51      1022\\nweighted avg       0.94      0.70      0.79      1022\\n')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Support Vector Machine classifier with class weight adjustment for imbalance\n",
    "svm_classifier = SVC(random_state=42, class_weight='balanced')\n",
    "\n",
    "# Train the SVM classifier\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set with the SVM classifier\n",
    "svm_predictions = svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the SVM classifier\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "svm_classification_report = classification_report(y_test, svm_predictions)\n",
    "\n",
    "(svm_accuracy, svm_classification_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b451fa",
   "metadata": {},
   "source": [
    "After training the Support Vector Machine (SVM) classifier with class weights adjusted for the imbalance, the results are quite different from the previous models:\n",
    "\n",
    "- Accuracy: 70.06%\n",
    "- Precision for classifying stroke: 12% (some stroke cases were correctly predicted)\n",
    "- Recall for classifying stroke: 82% (a large proportion of the actual stroke cases were identified)\n",
    "- F1-score for classifying stroke: 21%\n",
    "\n",
    "The SVM classifier has significantly improved in terms of recall for the stroke class compared to the Random Forest classifier, indicating that it's able to identify most of the actual stroke cases. However, the precision is low, which means there are a considerable number of false positives. This trade-off between precision and recall is common in imbalanced datasets.\n",
    "\n",
    "The decrease in overall accuracy compared to the Random Forest model reflects the SVM model's increased focus on the minority class. This is a good example of how accuracy is not always the most important metric in imbalanced class situations. Instead, the improvement in recall for the stroke class might be considered more valuable in a healthcare context, where missing out on potential stroke cases could have serious consequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bdd3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6aa1659d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7524461839530333,\n",
       " '              precision    recall  f1-score   support\\n\\n           0       0.99      0.75      0.85       972\\n           1       0.14      0.80      0.24        50\\n\\n    accuracy                           0.75      1022\\n   macro avg       0.56      0.78      0.55      1022\\nweighted avg       0.95      0.75      0.82      1022\\n')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Logistic Regression classifier with class weight adjustment for imbalance\n",
    "logreg_classifier = LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000)\n",
    "\n",
    "# Train the Logistic Regression classifier\n",
    "logreg_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set with the Logistic Regression classifier\n",
    "logreg_predictions = logreg_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the Logistic Regression classifier\n",
    "logreg_accuracy = accuracy_score(y_test, logreg_predictions)\n",
    "logreg_classification_report = classification_report(y_test, logreg_predictions)\n",
    "\n",
    "(logreg_accuracy, logreg_classification_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de56926",
   "metadata": {},
   "source": [
    "After training the Logistic Regression classifier with class weights adjusted for the imbalance, here are the results:\n",
    "\n",
    "- Accuracy: 75.24%\n",
    "- Precision for classifying stroke: 14% (indicating that it correctly predicted some stroke cases)\n",
    "- Recall for classifying stroke: 80% (a high number of actual stroke cases were identified)\n",
    "- F1-score for classifying stroke: 24%\n",
    "\n",
    "The Logistic Regression model performed similarly to the SVM in terms of recall, which is quite high, but the precision is still low, resulting in a modest F1-score. The overall accuracy is lower than that of the Random Forest classifier but higher than that of the SVM.\n",
    "\n",
    "Like the SVM, the Logistic Regression model's lower overall accuracy is due to it prioritizing the minority class (stroke cases), as seen by the high recall rate. This could be more desirable in a medical diagnosis context where it is crucial not to miss any potential stroke cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcc3bac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f55cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f5ebe48",
   "metadata": {},
   "source": [
    "When considering the performance of the various models we trained, it's essential to look beyond just accuracy, especially since we're dealing with an imbalanced dataset where the minority class—patients who have had a stroke—is of particular interest. Here’s a summary of the performance of each model on the test data:\n",
    "\n",
    "Decision Tree Classifier:\n",
    "- Accuracy: 91.78%\n",
    "- Precision for stroke: 15%\n",
    "- Recall for stroke: 14%\n",
    "- F1-score for stroke: 14%\n",
    "\n",
    "Random Forest Classifier:\n",
    "- Accuracy: 94.91%\n",
    "- Precision for stroke: 0%\n",
    "- Recall for stroke: 0%\n",
    "- F1-score for stroke: 0%\n",
    "\n",
    "Random Forest with Balanced Class Weights:\n",
    "- Accuracy: 95.01%\n",
    "- Precision for stroke: 0%\n",
    "- Recall for stroke: 0%\n",
    "- F1-score for stroke: 0%\n",
    "\n",
    "Support Vector Machine (SVM):\n",
    "- Accuracy: 70.06%\n",
    "- Precision for stroke: 12%\n",
    "- Recall for stroke: 82%\n",
    "- F1-score for stroke: 21%\n",
    "\n",
    "Logistic Regression with Balanced Class Weights:\n",
    "- Accuracy: 75.24%\n",
    "- Precision for stroke: 14%\n",
    "- Recall for stroke: 80%\n",
    "- F1-score for stroke: 24%\n",
    "\n",
    "Model Performance Evaluation:\n",
    "\n",
    "- Decision Tree: Moderately high accuracy but low precision and recall for predicting strokes, suggesting limited usefulness for our specific aim.\n",
    "\n",
    "- Random Forest (Standard and Balanced): High accuracy but failed to predict any stroke cases correctly, indicating it might be heavily biased towards the majority class.\n",
    "\n",
    "- SVM: Lower accuracy, but significantly higher recall, suggesting it is much better at identifying the minority class (stroke cases) than the other models. However, its precision is low, leading to a higher number of false positives.\n",
    "\n",
    "- Logistic Regression: Shows a good balance with decent recall and the highest F1-score among all models for the stroke class, making it potentially the most useful model for our purposes.\n",
    "\n",
    "Considering the aim is to predict strokes—a condition where failing to predict a positive case could be life-threatening—the models' ability to detect the positive class (high recall) is crucial. However, it is also important to maintain a reasonable precision to avoid too many false positives, which could lead to unnecessary anxiety and medical interventions.\n",
    "\n",
    "Best Performing Model:\n",
    "\n",
    "The Logistic Regression with Balanced Class Weights model appears to be the most suitable model for this task, based on our evaluations. It has the highest F1-score for stroke predictions, which balances precision and recall, making it the most effective at identifying true stroke cases while controlling for false positives better than the SVM.\n",
    "\n",
    "The SVM had a higher recall but lower F1-score due to many false positives, which may not be as preferable in a medical setting where false alarms can have significant consequences.\n",
    "\n",
    "It's important to note that these models can be further fine-tuned and evaluated using more sophisticated techniques and metrics, like the ROC-AUC score, to potentially improve their performance. Additionally, ensembling methods, more advanced oversampling techniques, and feature engineering could be explored to further enhance the model's ability to predict stroke events accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07213242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458fbbee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43242f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
